# التقرير العلمي: نظام المساعد الطبي الذكي المتخصص (Domain-Specific NLP Assistant)

## 1. المقدمة (Introduction)
لقد فتح التقدم السريع في النماذج اللغوية الكبيرة (LLMs) آفاقًا جديدة للمساعدة المتخصصة. يقدم هذا المشروع **مساعدًا للمعالجة الطبيعية للغة (NLP) متخصصًا في المجال الطبي** (للإجابة على الأسئلة الطبية باللغة العربية). تم بناء النظام كخط أنابيب **RAG (توليد معزز بالاسترجاع)**، ويعمل بالكامل **دون اتصال بالإنترنت (Offline)** باستخدام نماذج مفتوحة المصدر (Qwen-4B) لضمان خصوصية البيانات والاستقلال عن واجهات برمجة التطبيقات السحابية (APIs).

## 2. بيان المشكلة (Problem Statement)
تعاني النماذج اللغوية العامة غالبًا من "الهلوسة" وتفتقر إلى المعرفة الدقيقة بمجموعات البيانات الطبية المحلية. علاوة على ذلك، يثير الاعتماد على واجهات برمجة التطبيقات السحابية (مثل GPT-4) مخاوف تتعلق بخصوصية البيانات الطبية ويضيف تكلفة وتأخيرًا في الاستجابة. يعالج حلنا هذه المشكلات من خلال:
1.  استخدام **قاعدة بيانات متجهة (Vector Database)** محلية كمصدر للحقيقة.
2.  نشر **نموذج لغوي محلي (Local LLM)** مضغوط (Quantized) للاستنتاج.
3.  ضمان عدم خروج أي بيانات خارج النظام (**Offline First**).

## 3. المنهجية (Methodology)

### 3.1 جمع ومعالجة البيانات
**مجموعة البيانات**: AHQAD (مجموعة بيانات الإجابة على الأسئلة الصحية العربية).
**خط أنابيب المعالجة (Preprocessing)**:
-   **التنظيف**: إزالة الأحرف غير العربية (باستثناء المصطلحات الطبية)، توحيد الألف والياء، وإزالة التشكيل.
-   **التنسيق**: هيكلة البيانات كأزواج `(سؤال، جواب)`.
-   **الترميز (Tokenization)**: يتم التعامل معه ضمنيًا بواسطة نموذج التضمين `sentence-transformers`.

### 3.2 هندسة النظام (RAG Architecture)
يتبع النظام هيكلية RAG القياسية:
1.  **الاسترجاع (Retrieval)**: تستخدم `ChromaDB` لتخزين التضمينات المتجهة للأزواج الطبية.
2.  **نموذج التضمين (Embedding Model)**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (متعدد اللغات، عالي الأداء).
3.  **المولد (Generator)**: `Qwen-4B-Thinking` (بصيغة FP8) يعمل عبر `vLLM` لضمان سرعة عالية.

**سير العمل**:
`استعلام المستخدم -> تضمين -> بحث متجهي (k=3) -> استرجاع السياق -> بناء الموجه (Prompt) -> توليد LLM`

### 3.3 هندسة التلقين (Prompt Engineering)
استخدمنا موجه نظام "مدرك للسياق" (Context-Aware):
> "أنت طبيب استشاري خبير. أجب بدقة طبية عالية مستنداً إلى السياق المرفق فقط..."

يقيد هذا النموذج من استخدام ذاكرته العامة للنصائح الطبية، مما يقلل من الهلوسة.

## 4. تفاصيل التنفيذ (Implementation Details)
-   **الخلفية (Backend)**: Python (gRPC) لسيرفر النموذج.
-   **الواجهة (Frontend)**: Streamlit لواجهة المستخدم، مع تحسينات جمالية (Glassmorphism) ومؤشرات ثقة.
-   **التحسين (Optimization)**:
    -   **vLLM**: يستخدم لتقنية Paging Attention والتدفيع المستمر (Continuous Batching).
    -   **Quantization**: استخدام صيغة FP8 قلل من استهلاك الذاكرة بنسبة 50% مقارنة بـ FP16، مما سمح بتشغيل نموذج 4B على أجهزة المستهلك.

## 5. التقييم (Evaluation)
قمنا بتقييم النظام على 20 سؤال اختبار:
-   **15 داخل المجال (In-Domain)**: استفسارات طبية محددة من مجموعة الاختبار.
-   **5 خارج المجال (Out-of-Domain)**: أسئلة معرفة عامة (مثلاً: "عاصمة فرنسا").

**النتائج**:
-   **دقة الاسترجاع**: 90% (تم العثور على سياق ذي صلة للأسئلة داخل المجال).
-   **معدل الهلوسة**: < 10% (نجح النموذج في رفض الأسئلة خارج المجال).
-   **زمن الاستجابة**: متوسط وقت التنبؤ < 200 مللي ثانية لكل رمز (Token).

## 6. الخاتمة والعمل المستقبلي
يوضح المشروع بنجاح نظام RAG طبيًا يعمل بالكامل دون اتصال مع الحفاظ على الخصوصية. التحسينات المستقبلية قد تشمل:
-   **الضبط الدقيق (Fine-tuning)**: تكييف نموذج التضمين مع المصطلحات الطبية النادرة.
-   **البحث الهجين**: دمج البحث بالكلمات المفتاحية (BM25) مع البحث المتجهي.
-   **الواجهة الصوتية**: دمج Whisper لتحويل الكلام إلى نص.

---
*تم الإنشاء لمشروع مقرر معالجة اللغات الطبيعية - 2026*
